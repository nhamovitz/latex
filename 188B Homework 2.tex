\documentclass{article}

\usepackage[margin=1in]{geometry} 
\usepackage{amsmath, amsthm, amssymb, hyperref}

\newcommand{\R}{\mathbb{R}}  
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\bH}{\mathbb{H}}

\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\brac}[1]{\left[ #1 \right]}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\iprod}[2]{\left\langle #1, #2 \right\rangle}
% \newcommand{\lmap}[1]{\mathcal{L}(#1)}
% \newcommand{\lmap2}[1]{\mathcal{L}(#1, #2)}


\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\imag}{Im}

\newcommand{\comp}[2]{#1 \circ #2}

\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\range}{range}

\newenvironment{solution}{\begin{proof}[Solution]}{\end{proof}}
\newenvironment{definition}{\begin{proof}[Definition]}{\end{proof}}

\newcommand{\problem}[1]{\noindent \textbf{#1}}

% lol, lmao
\linespread{1.1}
\renewcommand{\baselinestretch}{1.17}

\begin{document}

% 117
% \renewcommand{\labelenumi}{(\alph{enumi})}

% ------------------------------------------ %
%                 START HERE                 %
% ------------------------------------------ %

\title{Homework 2} % Replace with appropriate title
\author{Nathaniel Hamovitz\\Math 118B, Ponce, W23}
\date{due 2023-01-26}

\maketitle

\problem{1. } % ✅
Let $f: [a, b] \to \R$ be a function such that $\exists M > 0, \exists \alpha > 1$ such that
$$\forall x, y \in \R, \qquad \abs{f(x) - f(y)} \le M\abs{x - y}^{\alpha}.$$
Prove that $f$ is constant.

\begin{proof}
    First we show that $f$ must be continuous on $[a, b]$. Let $\varepsilon > 0$. Consider $\delta = \paren{\frac{\varepsilon}{M}}^{\frac{1}{\alpha}}$. Then $\abs{x - y} < \delta$ implies $\abs{f(x) - f(y)} < \varepsilon$.

    Now we show that $f$ must also be differentiable. Let $x_0 \in [a, b]$ and let
    $$f'(x) = \lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0}.$$
    Note that
    \begin{align*}
        0 &\le \abs{\frac{f(x) - f(x_0)}{x - x_0}} \\
        &= \frac{\abs{f(x) - f(x_0)}}{x - x_0} \\
        &\le \frac{M\abs{x - x_0}^{\alpha}}{x - x_0} \\
        &= M\abs{x - x_0}^{\alpha - 1}
    \end{align*}
    and as $\alpha > 1$, this clearly goes to $0$ as $x \to x_0$. Thus by Squeeze Theorem $f' \equiv 0$.

    Finally we appeal to the Mean Value Theorem; the equation $f(x_2) - f(x_1) = (x_2 - x_1)f'(x)$ must, for all $x_1, x_2 \in (a, b)$, hold for some $x \in (a, b)$. But we know that $\forall x \in (a, b), f'(x) = 0$, and hence that $\forall x_1, x_2 \in (a, b), f(x_2) = f(x_1)$. Therefore $f$ is constant.    
\end{proof}

% ---

\problem{2. } % ✅
Let $n \in \N$, $n > 2$, $a, b \in \R$, and $f: \R \to \R$ be defined as
$$f(x) = x^n + ax + b.$$
Prove that $f$ vanishes in at most three points.

\begin{proof}
    We have $f'(x) = nx^{n - 1} + a$, and so at any critical point $f'(x) = 0$, 
    \begin{align*}
        0 &= nx^{n - 1} + a \\
        -\frac{a}{n} &= x^{n - 1} \\
        x &= \sqrt[n - 1]{-\frac{a}{n}}
    \end{align*}

    Such an expression has at most $2$ real solutions (1 when $n - 1$ is odd or $a = 0$. For $n - 1$ even, it depends on the sign of $a$: 2 solutions for $a < 0$ and $0$ for $a > 0$.)

    The Mean Value Theorem tells us that each vanishing point of a function after the first requires a corresponding point where $f'(x) = 0$ somewhere before, in order to satisfy $f(x_2) - f(x_1) = 0 = (x_2 - x_1)f'(x)$.

    Therefore $f$ vanishes in at most three points.    
\end{proof}

% ---

\problem{3. }
Show that $(\sin(x))' = \cos(x)$.
\begin{proof}
    
\end{proof}

% ---

\problem{4. }
For $a \ge 0$ define $f_a : \R \to \R$ by
$$f_a(x) = \begin{cases}
    x^a \sin\paren{\frac{1}{x}}, & \quad x > 0 \\
    0, & x \le 0
\end{cases}$$
For which values of $a$:
\begin{enumerate}
    \item \dots is $f_a$ continuous (on $\R$)?
    \begin{proof}
        As the composition of continuous functions, $f_a$ is continuous on $\R - \{0\}$ for all $a$. The only possible problem is at $x = 0$. For $a = 0$, $x^a = x^0 = 1$ and the function has crazy oscillations as $x \to 0$. But for any $a > 0$, $x^a$ becomes very small as $x \to 0$, and since the $\sin$ term is bounded, the whole thing reaches $0$ at $0$.        
    \end{proof}
    
    \item \dots does $f_a'(0)$ exist?
    \begin{proof}
        
    \end{proof}

    \item \dots is $f_a'$ continuous at $x = 0$?
    \begin{proof}
        
    \end{proof}

    \item \dots does $f_a''(0)$ exist?
    \begin{proof}
        
    \end{proof}

    \item \dots is $f_a''$ continuous at $x = 0$? 
    \begin{proof}
        
    \end{proof}

\end{enumerate}

% ---

\problem{Rudin 5-2. (pt 1)}
Suppose $f'(x) > 0$ in $(a, b)$. Prove that $f$ is strictly increasing in $(a, b)$.
\begin{proof}
    This is a simple application of the Mean Value Theorem. Let $x_1, x_2 \in (a, b)$ such that $x_2 > x_1$, the equation $f(x_1) - f(x_2) = (x_2 - x_1) f'(x)$ for \textit{some} $x \in (x_1, x_2)$. The RHS is positive, and so we have $f(x_1) > f(x_2)$.    
\end{proof}

\problem{Rudin 5-2. (pt 2)}
Now let $g$ be the inverse function of $f$. Prove that $g$ is differentiable, and that
$$g'(f(x)) = \frac{1}{f'(x)} \quad x \in (a, b).$$
\begin{proof}
    We first show that $g$ is differentiable on $(a, b)$. Let $x_0 \in (a, b)$. As $g = f^{-1}$, $x - x_0 = g(f(x)) - g(f(x_0))$. Hence
    \begin{align*}
        1 &= \frac{g(f(x)) - g(f(x_0))}{x - x_0} \\
        1 &= \frac{g(f(x)) - g(f(x_0))}{x - x_0} \cdot 1 \\
        1 &= \frac{g(f(x)) - g(f(x_0))}{x - x_0} \cdot \frac{f(x) - f(x_0)}{f(x) - f(x_0)} \\
        1 &= \frac{g(f(x)) - g(f(x_0))}{f(x) - f(x_0)} \cdot \frac{f(x) - f(x_0)}{x - x_0}
    \end{align*}
    Now take the limit on both sides as $x \to x_0$:
    \begin{align*}
        \lim_{x \to x_0} 1 &= \lim_{x \to x_0} \brac{\frac{g(f(x)) - g(f(x_0))}{f(x) - f(x_0)} \cdot \frac{f(x) - f(x_0)}{x - x_0}} \\
        1 &= \lim_{x \to x_0} \frac{g(f(x)) - g(f(x_0))}{f(x) - f(x_0)} \cdot \lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0}        
    \end{align*}
    Finally note that since $f'$ exists, $f$ is continuous, and thus as $x \to x_0$, $\abs{f(x) - f(x_0)} \to 0$. Hence, while the LHS remains 1, the RHS is in the form of derivative formulas, and we can write
    $1 = g'(f(x)) \cdot f'(x)$.
    Simply divide by $f'(x)$ (recalling that $f'$ is always positive) and we have
    $$g'(f(x)) = \frac{1}{f'(x)}.$$    
\end{proof}

% ---

\problem{Rudin 5-3. } % ✅
Suppose $g$ is a real function on $\R$, with bounded derivative (say $\abs{g'} \le M$). Fix $\varepsilon > 0$, and define $f(x) = x + \varepsilon g(x)$. Prove that $f$ is one-to-one if $\varepsilon$ is small enough.

\begin{proof}
    Let $x_1, x_2 \in \R$ (WLOG, suppose $x_1 \le x_2$) and suppose that $f(x_1) = f(x_2)$. Then $f(x_2) - f(x_1) = 0$ and so by the Mean Value Theorem either $x_2 - x_1 = 0$ or $f'(x) = 0$ for some $x \in (x_1, x_2)$.  
    
    Suppose for a contradiction that $f'(x) = 0$. We have $f'(x) = 1 + \varepsilon g'(x)$. Hence 
    \begin{align*}
        0 &= 1 + \varepsilon g'(x) \\
        g'(x) &= -\frac{1}{\varepsilon} \\
        \abs{g'(x)} &= \frac{1}{\varepsilon}       
    \end{align*}

    Now consider when $\displaystyle \varepsilon \le \frac{1}{M + 1}$. Then $\abs{g'(x)} = M + 1 > M$, which is a contradiction. Thus $x_2 = x_1$, and therefore $f$ is injective.
\end{proof}

% ---

\problem{Rudin 5-15. } % ✅❔
Suppose $a \in \R$, $f$ is a twice-differentiable real function on $(a, \infty)$, and $M_0$, $M_1$, $M_2$ are the least upper bounds of $\abs{f(x)}$, $\abs{f'(x)}$, $\abs{f''(x)}$, respectively, on $(a, \infty)$. Prove that
$$M_1^2 \le 4 M_0 M_2.$$

\begin{proof}
    It can be shown from the hypothesis that
    $\forall h > 0$,
    $$\abs{f'(x)} \le hM_2 + \frac{M_0}{h}.$$
    (This is given as a hint in Rudin; deriving it involves a clever reformulation of the Taylor Polynomial Theorem.) From there by a property of the supremum we have that $M_1 \le hM_2 + \frac{M_0}{h}$. All these values are nonnegative so we can square and find $M_1^2 \le h^2M_2^2 + \frac{M_0^2}{h^2} + 2M_2 M_0$. Call the RHS $g(h)$; as $M_1^2 \le g(h)$ holds for all positive $h$, it suffices to show there $\exists h > 0, g(h) = 4M_0 M_2$. Consider $h = \sqrt{\frac{M_0}{M_2}}$ (can be deduced by solving for $h$ directly or by considering the critical points of $g$); then
    \begin{align*}
        g(h) &= \frac{M_0}{M_2} M_2^2 + \frac{M_0^2}{\frac{M_0}{M_2}} + 2M_2 M_0 \\
        &= M_0 M_2 + M_0 M_2 + 2M_0 M_2 \\
        &= 4M_0 M_2         
    \end{align*}

    As the above holds for $h > 0$, we must also consider when $M_0 = 0$; in that case, $f \equiv 0$ and so $f = f' = f'' = 0$ and indeed $0^2 \le 4 \cdot 0 \cdot 0$.

    % what about $M_2 = 0$? Then,, f' must be constant with M_1 = f', and so $f = cx$, and sure c^2 \le inf * 0. that,, actually seems very undefined?
\end{proof}



\end{document}